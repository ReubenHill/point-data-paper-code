{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on this Notebook\n",
    "This loads a firedrake `DumbCheckpoint` file called `true-fields.h5` containing the values of $u_\\text{true}$ and $q_text{true}$ in `Function`s named `u_true` and `q_true` respectively which should have already been generated.\n",
    "When run as a python/ipython script, this expects argument specifiers as such:\n",
    "```\n",
    "$ python estimate-q.py num_points method\n",
    "```\n",
    "where `num_points` is the number of points to sample from `u_true` and `method` is one of:\n",
    " - `point-cloud` to minimise $J$\n",
    " - one of the following to minimise $J'$ by calculating $u_\\text{interpolated}$ via one of\n",
    "   - `nearest` to use `u_interpolated = scipy.interpolate.NearestNDInterpolator(xs, u_obs_vals)`\n",
    "   - `linear` to use `u_interpolated = scipy.interpolate.LinearNDInterpolator(xs, u_obs_vals, fill_value=0.0)`\n",
    "   - `clough-tocher` to use `u_interpolated = scipy.interpolate.CloughTocher2DInterpolator(xs, u_obs_vals, fill_value=0.0)`\n",
    "   - `gaussian` to use `u_interpolated = scipy.interpolate.Rbf(xs[:, 0], xs[:, 1], u_obs_vals, function='gaussian')`\n",
    "\n",
    "where `xs` are the point cloud coordinates and `u_obs_vals` the simulated measurementes of `u_true` at those coordinates with normally distributed random error added (variance $\\sigma^2$).\n",
    "\n",
    "Point cloud coordinates `xs`, values `u_obs_vals`, and standard deviation $\\sigma$ are taken from an HDF5 file `observed-data.h5` if available (stored as `xs_{num_points}`, `u_obs_vals_{num_points}`, and `sigma_{num_points}` respectively) or are generated and saved as such.\n",
    "\n",
    "Results are saved in a firedrake `DumbCheckpoint` file called `q-estimations.h5` containing $u_\\text{interpolated}$ (if calculated), $q_\\text{min}$ which minimises the functional $J$ or $J'$ and $q_\\text{err} = q_\\text{true} - q_\\text{min}$. \n",
    "These are named `u_interpolated_{method}_{num_points}`, `q_min_{method}_{num_points}` and `q_err_{method}_{num_points}` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "\n",
    "We want to find out how the solution of our inverse problem converges as we increase the number of points for both the new and traditional methods of data interpolation.\n",
    "\n",
    "If we have what is known as **\"posterior consistency\"** then we expect that the error in our solution, when compared to the true solution, will always decrease as we increase the number of points we are assimilating.\n",
    "\n",
    "## Posterior Consistency\n",
    "\n",
    "From a Bayesian point of view, the regularisation we choose and the weighting we give it encode information about our assumed prior probability distribution of $q$ before we start assimilating data (adding observations).\n",
    "Take, for example, the regularisation used in the this problem\n",
    "\n",
    "$$\n",
    "\\alpha^2\\int_\\Omega|\\nabla q|^2dx\n",
    "$$\n",
    "\n",
    "which asserts a prior that the solution $q$ which minimises $J$ should be smooth and gives a weighting $\\alpha$ to the assertion.\n",
    "If we have posterior consistency, the contribution of increasing numbers of measurements $u_{obs}$ should increase the weighting of our data relative to our prior and we should converge towards the true solution.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "Our two methods minimise two different functionals. \n",
    "The first minimises $J$\n",
    "\n",
    "$$\n",
    "J[u, q] = \\underbrace{\n",
    "                        \\int_{\\Omega_v} ( u_{\\text{obs}} - \\mathcal{I}_{\\text{P0DG}(\\Omega_v)}(u) )^2 dx\n",
    "                        }_{J_{\\text{model-data misfit}}^{\\text{point}}} + \n",
    "            \\underbrace{\n",
    "                        \\alpha^2\\int_\\Omega|\\nabla q|^2 dx\n",
    "                        }_{J_{\\text{regularisation}}}\n",
    "$$\n",
    "\n",
    "whilst the second minimises $J'$\n",
    "\n",
    "$$\n",
    "J'[u, q] = \\underbrace{\n",
    "                        \\int_{\\Omega} ( u_{\\text{interpolated}} - u )^2 dx\n",
    "                        }_{J_{\\text{model-data misfit}}^{\\text{field}}} + \n",
    "            \\underbrace{\n",
    "                        \\alpha^2\\int_\\Omega|\\nabla q|^2 dx\n",
    "                        }_{J_{\\text{regularisation}}}\n",
    "$$\n",
    "\n",
    "**where $\\alpha$ is an appropriate value found with an l-curve analysis.**\n",
    "\n",
    "As set up here increasing the number of points to assimilate has the effect of increasing the size of the misfit term in $J$ so we expect to converge to $q_\\text{true}$ as the number of measurements increases.\n",
    "\n",
    "As we increase the number of measurements in $J'$ we hope that our calculated $u_\\text{interpolated}$ approaches $u$ (to therefore minimise the misfit). There is, however, no mechanism to cause the misfit term to increase relative to the regularization term.\n",
    "\n",
    "We therefore predict that minimising $J$ will display posterior consistency and that minimising the various $J'$ for each $u_\\text{interpolated}$ will not.\n",
    "\n",
    "## Hypothesis Amendment! A note on finite element method error\n",
    "Note that our solutions all exist in finite element spaces which are usually approximations of a true solution with some error that (hopefully) decreases as mesh density increase and solution space order increase.\n",
    "Since I am comparing to a solution $u_\\text{true}$ in CG2 space I expect, at best, that we will converge to $u_\\text{true}$ when we have, on average, enough points per cell to fully specify the lagrange polynomials in that cell.\n",
    "Were we in CG1 this would be 3 points per cell (I can't remember how many we would need for CG2!) to give convergence if those measurements had no noise.\n",
    "Since our measurements are noisy I do not expect actual convergence, but I anticipate some slowing in convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import (\n",
    "    LinearNDInterpolator,\n",
    "    NearestNDInterpolator,\n",
    "    CloughTocher2DInterpolator,\n",
    "    Rbf,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import firedrake\n",
    "import firedrake_adjoint\n",
    "\n",
    "from firedrake import Constant, cos, sin\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi as Ï€\n",
    "from numpy import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import os, sys\n",
    "\n",
    "currentdir = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Estimate q using pyadjoint with a given number of point samples of u_true and chosen method. Expects to find a Firedrake checkpoint file \\'true-fields.h5\\' in the import directory.')\n",
    "parser.add_argument('num_points', type=int, help='The number of points to sample from u_true. Points and measurements be identified from \\'observed-data.h5\\' or created and saved to it.')\n",
    "parser.add_argument('method', help=\"The method to use: one of point-cloud, nearest, linear, clough-tocher, or gaussian\")\n",
    "try:\n",
    "    args = parser.parse_args()\n",
    "    num_points = args.num_points\n",
    "    method = args.method\n",
    "except:\n",
    "    import warnings\n",
    "    warnings.warn(f'Failed to parse arguments. Defaulting to num_points = 4 and method = point-cloud')\n",
    "    num_points = 4\n",
    "    method = 'point-cloud'\n",
    "\n",
    "methods = ['point-cloud', 'nearest', 'linear', 'clough-tocher', 'gaussian']\n",
    "\n",
    "# If running as notebook use default of 4 points and method 'point-cloud'\n",
    "if method not in methods:\n",
    "    import warnings\n",
    "    warnings.warn(f'Got unexpected method argument {method} defaulting to point-cloud')\n",
    "    method = 'point-cloud'\n",
    "    \n",
    "print(f\"Running with {num_points} points and method {method}\")\n",
    "\n",
    "seed = 1729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = firedrake.UnitSquareMesh(32, 32)\n",
    "\n",
    "# Solution Space\n",
    "V = firedrake.FunctionSpace(mesh, family='CG', degree=2)\n",
    "\n",
    "# q (Control) Space\n",
    "Q = firedrake.FunctionSpace(mesh, family='CG', degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get $q_\\text{true}$ and $u_\\text{true}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_true = firedrake.Function(V, name='q_true')\n",
    "u_true = firedrake.Function(V, name='u_true')\n",
    "filename = os.path.join(currentdir, 'true-fields')\n",
    "with firedrake.DumbCheckpoint(filename, mode=firedrake.FILE_READ) as chk:\n",
    "    chk.load(q_true, name='q_true')\n",
    "    chk.load(u_true, name='u_true')\n",
    "    \n",
    "print(\"Have fake q_true and u_true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Save or Load \"Observed\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = os.path.join(currentdir, 'observed-data.h5')\n",
    "\n",
    "try:\n",
    "    # Load if available\n",
    "    with h5py.File(filename, 'r') as file:\n",
    "        xs = file[f\"xs_{num_points}\"][:]\n",
    "        u_obs_vals = file[f\"u_obs_vals_{num_points}\"][:]\n",
    "        Ïƒ = firedrake.Constant(file[f\"sigma_{num_points}\"])\n",
    "        print(f\"Loaded xs, u_obs_vals and sigma for {num_points} points.\")\n",
    "except (OSError, KeyError) as e:\n",
    "    # Generate\n",
    "    np.random.seed(0)\n",
    "    xs = np.random.random_sample((num_points, 2))\n",
    "    signal_to_noise = 20\n",
    "    U = u_true.dat.data_ro[:]\n",
    "    u_range = U.max() - U.min()\n",
    "    Ïƒ = firedrake.Constant(u_range / signal_to_noise)\n",
    "    generator = random.default_rng(seed)\n",
    "    Î¶ = generator.standard_normal(len(xs))\n",
    "    u_obs_vals = np.array(u_true.at(xs)) + float(Ïƒ) * Î¶\n",
    "    # Save\n",
    "    with h5py.File(filename, 'a') as file:\n",
    "        file.create_dataset(f\"xs_{num_points}\", data=xs)\n",
    "        file.create_dataset(f\"u_obs_vals_{num_points}\", data=u_obs_vals)\n",
    "        file.create_dataset(f\"sigma_{num_points}\", data=Ïƒ.values()[0])\n",
    "    print(f\"Generated and saved xs, u_obs_vals and sigma for {num_points} points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve\n",
    "\n",
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Constant(1.0)\n",
    "k0 = Constant(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run forward model with `q = 0` as first guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import exp, inner, grad, dx\n",
    "\n",
    "print('Running forward model')\n",
    "u = firedrake.Function(V)\n",
    "v = firedrake.TestFunction(V)\n",
    "q = firedrake.Function(Q)\n",
    "bc = firedrake.DirichletBC(V, 0, 'on_boundary')\n",
    "F = (k0 * exp(q) * inner(grad(u), grad(v)) - f * v) * dx\n",
    "firedrake.solve(F == 0, u, bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulate $J$ or $J'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'point-cloud':\n",
    "    \n",
    "    # Need bigger alpha here to be closer to L-curve turning point which\n",
    "    # keep the problem well-posed\n",
    "    Î± = firedrake.Constant(0.2)\n",
    "\n",
    "    # Store data on the point_cloud using a vertex only mesh\n",
    "    print('Creating VertexOnlyMesh')\n",
    "    point_cloud = firedrake.VertexOnlyMesh(mesh, xs)\n",
    "    print('Creating P0DG(VertexOnlyMesh) space')\n",
    "    P0DG = firedrake.FunctionSpace(point_cloud, 'DG', 0)\n",
    "    print('Creating u_obs')\n",
    "    u_obs = firedrake.Function(P0DG, name=f'u_obs_{method}_{num_points}')\n",
    "    u_obs.dat.data[:] = u_obs_vals\n",
    "    \n",
    "    print('Assembling J')\n",
    "    misfit_expr = (u_obs - firedrake.interpolate(u, P0DG))**2\n",
    "\n",
    "else:\n",
    "    \n",
    "    Î± = firedrake.Constant(0.02)\n",
    "\n",
    "    # Interpolating the mesh coordinates field (which is a vector function space)\n",
    "    # into the vector function space equivalent of our solution space gets us\n",
    "    # global DOF values (stored in the dat) which are the coordinates of the global\n",
    "    # DOFs of our solution space. This is the necessary coordinates field X.\n",
    "    print('Getting coordinates field X')\n",
    "    Vc = firedrake.VectorFunctionSpace(mesh, V.ufl_element())\n",
    "    X = firedrake.interpolate(mesh.coordinates, Vc).dat.data_ro[:]\n",
    "\n",
    "    # Pick the appropriate \"interpolate\" method needed to create\n",
    "    # u_interpolated given the chosen method\n",
    "    print(f'Creating {method} interpolator')\n",
    "    if method == 'nearest':\n",
    "        interpolator = NearestNDInterpolator(xs, u_obs_vals)\n",
    "    elif method == 'linear':\n",
    "        interpolator = LinearNDInterpolator(xs, u_obs_vals, fill_value=0.0)\n",
    "    elif method == 'clough-tocher':\n",
    "        interpolator = CloughTocher2DInterpolator(xs, u_obs_vals, fill_value=0.0)\n",
    "    elif method == 'gaussian':\n",
    "        interpolator = Rbf(xs[:, 0], xs[:, 1], u_obs_vals, function='gaussian')\n",
    "    print('Interpolating to create u_interpolated')\n",
    "    u_interpolated = firedrake.Function(V, name=f'u_interpolated_{method}_{num_points}')\n",
    "    u_interpolated.dat.data[:] = interpolator(X[:, 0], X[:, 1])\n",
    "    \n",
    "    print('Assembling J\\'')\n",
    "    misfit_expr = (u_interpolated - u)**2    \n",
    "    \n",
    "regularisation_expr = Î±**2 * inner(grad(q), grad(q))\n",
    "# Assembled J is here either J or J_prime depending on the misfit expression\n",
    "J = firedrake.assemble(misfit_expr * dx) + firedrake.assemble(regularisation_expr * dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimise to Estimate $q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting qÌ‚ (control varaible) and JÌ‚ (reduced functional)')\n",
    "qÌ‚ = firedrake_adjoint.Control(q)\n",
    "JÌ‚ = firedrake_adjoint.ReducedFunctional(J, qÌ‚)\n",
    "\n",
    "print('Minimising JÌ‚ to get q_min')\n",
    "q_min = firedrake_adjoint.minimize(\n",
    "    JÌ‚, method='Newton-CG', options={'disp': True}\n",
    ")\n",
    "# Rename for saving\n",
    "q_min.rename(name=f'q_min_{method}_{num_points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating q error field')\n",
    "q_err = firedrake.Function(Q, name=f'q_err_{method}_{num_points}').assign(q_min-q_true)\n",
    "print('Calculating L2 error norm')\n",
    "l2norm = firedrake.norm(q_err, \"L2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(currentdir, 'q-estimations')\n",
    "\n",
    "with firedrake.DumbCheckpoint(filename, mode=firedrake.FILE_UPDATE) as chk:\n",
    "    if method != 'point-cloud':\n",
    "        # Not necessary to save u_obs since it's already saved as u_obs_vals\n",
    "        print('Saving u_interpolated')\n",
    "        chk.store(u_interpolated)\n",
    "    print('Saving q_min')\n",
    "    chk.store(q_min)\n",
    "    print('Saving q_err')\n",
    "    chk.store(q_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we saved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with firedrake.DumbCheckpoint(filename, mode=firedrake.FILE_UPDATE) as chk:\n",
    "    if method != 'point-cloud':\n",
    "        print('Loading u_interpolated')\n",
    "        u_interpolated_2 = firedrake.Function(V)\n",
    "        chk.load(u_interpolated_2, name=f'u_interpolated_{method}_{num_points}')\n",
    "        assert np.allclose(u_interpolated_2.dat.data_ro[:], u_interpolated.dat.data_ro[:])\n",
    "    print('Loading q_min')\n",
    "    q_min_2 = firedrake.Function(Q)\n",
    "    chk.load(q_min_2, name=f'q_min_{method}_{num_points}')\n",
    "    assert np.allclose(q_min_2.dat.data_ro[:], q_min.dat.data_ro[:])\n",
    "    print('Loading q_err')\n",
    "    q_err_2 = firedrake.Function(Q)\n",
    "    chk.load(q_err_2, name=f'q_err_{method}_{num_points}')\n",
    "    assert np.allclose(q_err_2.dat.data_ro[:], q_err.dat.data_ro[:])\n",
    "    \n",
    "print('Success!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
